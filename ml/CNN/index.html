<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="KbCOz5IFs80bU-psVUCv9C7SOLzVWto8d7_5ZSsX7I0"><meta name="baidu-site-verification" content="codeva-KcLqIZYGXd"><link rel="alternate" type="application/rss+xml" title="藏器于身" href="https://gality.cn/rss.xml"><link rel="alternate" type="application/atom+xml" title="藏器于身" href="https://gality.cn/atom.xml"><link rel="alternate" type="application/json" title="藏器于身" href="https://gality.cn/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/css/app.css?v=0.2.5"><meta name="keywords" content="机器学习,CNN,卷积神经网络,图像处理"><link rel="canonical" href="https://gality.cn/ml/CNN/"><title>CNN | Network Architecture Designed for Image - 机器学习 | Samadhi = 藏器于身 = 待时而动</title><meta name="generator" content="Hexo 6.3.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">CNN | Network Architecture Designed for Image</h1><div class="meta"><span class="item" title="创建时间：2024-02-05 11:12:37"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2024-02-05T11:12:37+08:00">2024-02-05</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>3.1k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>6 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Samadhi</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="http://imgcdn.gality.cn/blog/3ywxuv.jpg"></li><li class="item" data-background-image="http://imgcdn.gality.cn/blog/6nuw7q.png"></li><li class="item" data-background-image="http://imgcdn.gality.cn/blog/9xfu49.png"></li><li class="item" data-background-image="http://imgcdn.gality.cn/blog/kapsd3.jpg"></li><li class="item" data-background-image="http://imgcdn.gality.cn/blog/2023-08-19-wallhaven-qzmlj5_2560x1440.png"></li><li class="item" data-background-image="http://imgcdn.gality.cn/blog/70869m.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/ml/" itemprop="item" rel="index" title="分类于 机器学习"><span itemprop="name">机器学习</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://gality.cn/ml/CNN/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/avatar.png"><meta itemprop="name" content="Gality"><meta itemprop="description" content="待时而动, 安全杂记 & 日常随感"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="藏器于身"></span><div class="body md" itemprop="articleBody"><div class="note info no-icon"><p>卷积神经网络（Convolutional Neural Network）是一种专为图像处理设计的神经网络结构。相比于全连接神经网络结构，卷积神经网络在面对图像相关任务时有突出的表现，这是因为这种特殊的网络结构的设计思路与图像本身的特征紧密相关，也正因为如此，如果想将 CNN 应用于其他模态任务中，应根据具体模态的特征对网络进行修改。「著名的 AlphaGo 就是基于 CNN 结构来进行学习的」</p></div><h1 id="问题引入"><a class="anchor" href="#问题引入">#</a> 问题引入</h1><p>假设我们希望用机器学习来实现一个图片分类任务，模型的输入是一张图片，模型的输出是其所属的分类。以一个 <code>100x100</code> 像素的图片为例（作为对比，我们常说的 4K 分辨率指 <code>3840x2160</code> 像素）。</p><p><img data-src="http://imgcdn.gality.cn/blog/vldzu5.jpg" alt="图片处理" height="350"></p><p>图片可以看作是一个 3 维的 tensor，三个维度分别为：长、宽、通道。对于彩色图片来说，有三个通道，对应着<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zNjc4MjMzMTk="> RGB 三种颜色</span>（计算机存储图片的原理）。由于神经网络的输入只能是一个向量（2 维），所以为了让神经网络能读取一个图片，我们需要先将三维 tensor “平坦化”，将三维的 tensor 按通道维度排列成 2 维的向量，在这个例子中，向量的大小为 <code>300x100</code> 。</p><p>我们先考虑用一个全连接神经网络来处理这个图片，假设第一层有 1000 个神经元，任意一个输入到任意一个神经元之间都应存在一个 “权重”。此时，第一层将有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mo>×</mo><mn>300</mn><mo>×</mo><mn>1000</mn><mo>=</mo><mn>1</mn><msup><mn>0</mn><mn>7</mn></msup></mrow><annotation encoding="application/x-tex">100 \times 300 \times 1000 = 10^7</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">3</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span> 个 “权重”，这还是在不考虑 “偏置”，不考虑 “多层” 网络的情况下。</p><p><span class="red">事实上，想要更新如此海量的参数，对算力要求实在太过庞大，根本就 “train” 不起来。</span></p><h1 id="简化基于局部特征来简化网络结构"><a class="anchor" href="#简化基于局部特征来简化网络结构">#</a> 简化：基于局部特征来简化网络结构</h1><p>人类在识别图片时，图片中的大部分的内容其实是无用的，人类其实是通过一些<strong>局部特征</strong>来识别物体的，例如下面的图片，第一眼看上去非常像一只乌鸦，因为我们首先看到了 “喙”，结合 “黑色” 的特征，我们很容易联想到乌鸦。但是再往下看，当我们看到了 “尾巴” 这个特征后，我们会反应过来，原来这是一个猫。但是无论我们怎么识别这个动物，周围的黄色地板别没有为我们提供任何有效信息，把它们去掉也并不影响我们识别出这个动物。</p><p><img data-src="http://imgcdn.gality.cn/blog/fih9ra.png" alt="“乌鸦”猫猫" height="210"></p><h2 id="让模型只关注局部细节"><a class="anchor" href="#让模型只关注局部细节">#</a> 让模型只关注局部细节</h2><p>受上面的观察启发，我们发现在进行图像处理时，神经网络其实并不需要整个图像来作为输入，只要神经网络能识别出图片中物体的某些特征就足够完成识别任务了。因此，我们可以考虑按一定的规则来将原图片划分成多个 “小图片”，给一个小图片分配<strong>一个或多个神经元</strong>来学习。</p><p><img data-src="http://imgcdn.gality.cn/blog/wqu0cs.jpg" alt="模型只看细节" height="350"></p><p>假设我们将图片划分成 <code>3x3</code> 像素（需要根据实际情况调整，能覆盖住特征即可，覆盖不完全也可以，后面会说）的小图片，并且令每 3 个神经元学习一个小图片，那么此时，对于一个神经元来说，所需更新的 “权重” 就从过去的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">3 \times 10^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span> 个降低到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn><mo>×</mo><mn>3</mn><mo>=</mo><mn>9</mn></mrow><annotation encoding="application/x-tex">3\times3\times3=9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.72777em;vertical-align:-.08333em"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2222222222222222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222222222222222em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">3</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.64444em;vertical-align:0"></span><span class="mord">9</span></span></span></span> 个，所需运算量就会大大减小了，这就是一种简化。</p><p><img data-src="http://imgcdn.gality.cn/blog/7qunhq.png" alt="感受野" height="350"></p><p>其中，每个神经元可感知的区域，就叫做<strong>感受野（receptive field）</strong>。</p><h2 id="常见问题"><a class="anchor" href="#常见问题">#</a> 常见问题</h2><h3 id="感受野是否可以重叠为什么"><a class="anchor" href="#感受野是否可以重叠为什么">#</a> 感受野是否可以重叠，为什么？</h3><p>感受野可以重叠，也必须重叠，因为在划定感受野时我们并不能保证识别物体所需的特征就正好完整的落在感受野内，所以，最好逐像素的划定感受野，以保证特征可以完整的出现在某些神经元的感受野中。每个感受野相隔的距离称为<strong>步长（stride）</strong>。</p><h3 id="感受野的设计是否有规范"><a class="anchor" href="#感受野的设计是否有规范">#</a> 感受野的设计是否有规范？</h3><p>感受野可以根据任务需要随意设计，例如感受野可以只看某个通道、或者感受野的形状也可以是长方形等等、或者也是可以设计不同大小的感受野，总之，一切根据任务需要来。</p><h3 id="感受野越过图像边界怎么办"><a class="anchor" href="#感受野越过图像边界怎么办">#</a> 感受野越过图像边界怎么办？</h3><p>可以直接不填充，也可以根据需要对图像的边缘进行填充，同样，具体怎么填充也可以随意设计。</p><h3 id="经典设计"><a class="anchor" href="#经典设计">#</a> 经典设计</h3><p>这里提供一种经典设计：每个感受野分配 64 个神经元，感受野大小 <code>3x3</code> ，步长为 2，边缘需要进行填充。</p><h1 id="简化基于相似特征简化训练过程"><a class="anchor" href="#简化基于相似特征简化训练过程">#</a> 简化：基于相似特征简化训练过程</h1><p>人类在识别图片的过程中常常会忽略一点，那就是我们要识别的物体可以在图片中的任意位置，人类会自动忽略物体相对在图片中相对位置的区别，但是对于神经网络来说，由于是不同的神经元来感知不同的区域，所以可能存在某一特征换了个位置，另外一个神经元识别不出的情况。</p><p><img data-src="http://imgcdn.gality.cn/blog/ge8iuo.jpg" alt="同一特征出现在不同位置" height="350"></p><h2 id="让不同感受野的神经元共享参数"><a class="anchor" href="#让不同感受野的神经元共享参数">#</a> 让不同感受野的神经元共享参数</h2><p>神经网络学习的过程其实就是确定一组参数的过程，我们从单个神经元的角度来看，神经元对某特征的识别可以对应到该神经元的一组参数上，所以，如果我们让不同的神经元共享这一组参数，则可以实现让不同的神经元都可以识别同一特征。这里需要强调的的是，这里的不同的神经元必须是<strong>不同感受野</strong>的神经元，由于不同的感受野的神经元的输入不同，即使共享同一组参数，仍然会有不同的输出；而如果是同一感受野的神经元的话，共享同一组参数则会使不同神经元输出相同的结果，这并不是我们希望看到的。</p><p><img data-src="http://imgcdn.gality.cn/blog/53hkro.jpg" alt="不同感受野的神经元共享同一组参数" height="350"></p><p>进一步来说，其实就是将一组参数和一个特征绑定，记得上文中提到的要让多个神经元来感受同一个感受野吗？是的，让 64 个神经元感受一个感受野，其实就是在模型中预留了 64 个 “可更新” 的特征位，该模型最多可以从图片中提取 64 个不同的特征，且任意一个感受野的神经元都可以识别这种特征。感受同一个感受野的不同神经元我们以 <code>filter x</code> 来命名，第一个称为 <code>filter 1</code> ，以此类推。</p><p>这样，我们就可以在训练过程中<strong>同步更新多个神经元</strong>，任意一个神经元学习到某种特征后，其他感受野的对应的 <code>filter</code> 也会自动的学会这种特征，从而大大简化训练的过程，同时提高模型的泛化能力。</p><h1 id="从filter的角度看待训练过程"><a class="anchor" href="#从filter的角度看待训练过程">#</a> 从 filter 的角度看待训练过程</h1><p>前面说过，一个 <code>filter</code> 识别一种特征，这个说法可能稍微有些抽象，我们来给出一个具体的例子：输入是一个 <code>6x6</code> 像素的黑白图片（通道数为 1），感受野为 <code>3x3</code> ，每个感受野设置 64 个神经元去学习，步长为 1，在神经网络中我们仍只考虑 “权重”。</p><h2 id="一个filter识别一种特征"><a class="anchor" href="#一个filter识别一种特征">#</a> 一个 filter 识别一种特征</h2><p>首先来说明为什么一个 <code>filter</code> 可以识别一种特征。</p><p><img data-src="http://imgcdn.gality.cn/blog/lxcfqf.jpg" alt="一个filter识别一种特征" height="350"></p><p>假设 <code>Filter 1</code> 就是一个主对角线全为 1，其他元素都为 - 1 的权重矩阵，那么当且仅当感受野中主对角线全为 1，其他元素全 0 时才能，该神经元的输出可以取得最大值 3，即 <code>Filter 1</code> 识别了特征：有一条从左上到右下的线。</p><h2 id="从小图片到整个图片"><a class="anchor" href="#从小图片到整个图片">#</a> 从小图片到整个图片</h2><p><img data-src="http://imgcdn.gality.cn/blog/5ftedn.jpg" alt="多层CNN" height="350"></p><p>因为一个感受野设置了 64 个神经元，所以第一层卷积层处理后得到的是一个 64 通道，大小为 <code>4x4</code> 的特征 tensor，将该输出交给下一层卷积层，下一个卷积层设置的感受野仍为 <code>3x3</code> ，但是这时，由于 <code>3x3</code> 的感受野中的每一个 <code>Feature</code> 都是从原图片中 <code>3x3x1</code> 的小图片中提取的，即每一个 <code>Feature</code> 都包含了 <code>3x3x1</code> 的像素信息，那么第二层卷积层所能 “感受” 的范围其实是原图片中 <code>5x5x1</code> 大小的区域。</p><p>随着卷积层的增多，后面的卷积层中的神经元 “感受” 的范围就会<strong>越来越大</strong>。</p><h1 id="简化基于图片的压缩来简化计算量"><a class="anchor" href="#简化基于图片的压缩来简化计算量">#</a> 简化：基于图片的压缩来简化计算量</h1><p>一般来说，对图片进行降采样并不影响图片的识别，我们可以采用某种方法来将多个像素合成成一个像素，从而大幅减少图片中的总像素点数，这过程称为 <code>Pooling</code> 。以 <code>Max Pooling</code> 为例， <code>Max Pooling</code> 就是用一个区域内最大的值代替该区域的所有值，从而压缩图片大小。</p><p>需要注意的是，无论怎样 <code>Pooling</code> 都一定会减少图片的特征。这种方法一般在过去算力紧张时使用，现在的 CNN 中已经在慢慢减少，甚至完全不使用 <code>Pooling</code> 技术了。</p><h1 id="总结"><a class="anchor" href="#总结">#</a> 总结</h1><p>卷积神经网络其实就是一种专为处理图像而设计的网络结构。全连接层可以处理任何任务，同样的，也意味着他并不擅长任何任务。在全连接的基础上加入 “感受野” 和 “参数共享”，就诞生了卷积卷积神经网络。</p><p><img data-src="http://imgcdn.gality.cn/blog/gch9wd.png" alt="Benefit of Convolutional Layer" height="350"></p><h1 id="参考"><a class="anchor" href="#参考">#</a> 参考</h1><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMVRENHkxMzdtUD9wPTIw">https://www.bilibili.com/video/BV1TD4y137mP?p=20</span></li></ul><br><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="ic i-tag"></i> 机器学习</a> <a href="/tags/CNN/" rel="tag"><i class="ic i-tag"></i> CNN</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" rel="tag"><i class="ic i-tag"></i> 图像处理</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-02-05 23:30:59" itemprop="dateModified" datetime="2024-02-05T23:30:59+08:00">2024-02-05</time> </span><span id="ml/CNN/" class="item leancloud_visitors" data-flag-title="CNN | Network Architecture Designed for Image" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/wechatpay.png" alt="Gality 微信支付"><p>微信支付</p></div><div><img data-src="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/alipay.png" alt="Gality 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Gality <i class="ic i-at"><em>@</em></i>藏器于身</li><li class="link"><strong>本文链接：</strong> <a href="https://gality.cn/ml/CNN/" title="CNN | Network Architecture Designed for Image">https://gality.cn/ml/CNN/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/scientific-research/thesis-reading/%20Blockchain%20Imitation%20Game/" itemprop="url" rel="prev" data-background-image="http:&#x2F;&#x2F;imgcdn.gality.cn&#x2F;blog&#x2F;e2h6c4.jpg" title="论文阅读｜ The Blockchain Imitation Game"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 论文阅读</span><h3>论文阅读｜ The Blockchain Imitation Game</h3></a></div><div class="item right"><a href="/ml/transformer/" itemprop="url" rel="next" data-background-image="http:&#x2F;&#x2F;imgcdn.gality.cn&#x2F;blog&#x2F;jzaav9.jpg" title="Transformer 详解"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 机器学习</span><h3>Transformer 详解</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%BC%95%E5%85%A5"><span class="toc-number">1.</span> <span class="toc-text">问题引入</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E5%9F%BA%E4%BA%8E%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81%E6%9D%A5%E7%AE%80%E5%8C%96%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text">简化：基于局部特征来简化网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A9%E6%A8%A1%E5%9E%8B%E5%8F%AA%E5%85%B3%E6%B3%A8%E5%B1%80%E9%83%A8%E7%BB%86%E8%8A%82"><span class="toc-number">2.1.</span> <span class="toc-text">让模型只关注局部细节</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.</span> <span class="toc-text">常见问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%84%9F%E5%8F%97%E9%87%8E%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%8F%A0%E4%B8%BA%E4%BB%80%E4%B9%88"><span class="toc-number">2.2.1.</span> <span class="toc-text">感受野是否可以重叠，为什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%98%AF%E5%90%A6%E6%9C%89%E8%A7%84%E8%8C%83"><span class="toc-number">2.2.2.</span> <span class="toc-text">感受野的设计是否有规范？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%84%9F%E5%8F%97%E9%87%8E%E8%B6%8A%E8%BF%87%E5%9B%BE%E5%83%8F%E8%BE%B9%E7%95%8C%E6%80%8E%E4%B9%88%E5%8A%9E"><span class="toc-number">2.2.3.</span> <span class="toc-text">感受野越过图像边界怎么办？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.2.4.</span> <span class="toc-text">经典设计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E5%9F%BA%E4%BA%8E%E7%9B%B8%E4%BC%BC%E7%89%B9%E5%BE%81%E7%AE%80%E5%8C%96%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">简化：基于相似特征简化训练过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A9%E4%B8%8D%E5%90%8C%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E5%85%B1%E4%BA%AB%E5%8F%82%E6%95%B0"><span class="toc-number">3.1.</span> <span class="toc-text">让不同感受野的神经元共享参数</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8Efilter%E7%9A%84%E8%A7%92%E5%BA%A6%E7%9C%8B%E5%BE%85%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">从 filter 的角度看待训练过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E4%B8%AAfilter%E8%AF%86%E5%88%AB%E4%B8%80%E7%A7%8D%E7%89%B9%E5%BE%81"><span class="toc-number">4.1.</span> <span class="toc-text">一个 filter 识别一种特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E5%B0%8F%E5%9B%BE%E7%89%87%E5%88%B0%E6%95%B4%E4%B8%AA%E5%9B%BE%E7%89%87"><span class="toc-number">4.2.</span> <span class="toc-text">从小图片到整个图片</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%89%87%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%9D%A5%E7%AE%80%E5%8C%96%E8%AE%A1%E7%AE%97%E9%87%8F"><span class="toc-number">5.</span> <span class="toc-text">简化：基于图片的压缩来简化计算量</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">6.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">7.</span> <span class="toc-text">参考</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/ml/nndl/nndl-1/" rel="bookmark" title="《神经网络与深度学习》笔记（1）">《神经网络与深度学习》笔记（1）</a></li><li><a href="/ml/homework/HW-1/" rel="bookmark" title="李宏毅ML2022-Spring大作业01｜COVID-19 Cases Prediction (Regression)">李宏毅ML2022-Spring大作业01｜COVID-19 Cases Prediction (Regression)</a></li><li><a href="/ml/regularization/" rel="bookmark" title="ML Regularization">ML Regularization</a></li><li class="active"><a href="/ml/CNN/" rel="bookmark" title="CNN | Network Architecture Designed for Image">CNN | Network Architecture Designed for Image</a></li><li><a href="/ml/transformer/" rel="bookmark" title="Transformer 详解">Transformer 详解</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Gality" data-src="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/images/avatar.png"><p class="name" itemprop="name">Gality</p><div class="description" itemprop="description">安全杂记 & 日常随感</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">29</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">17</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">43</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL0dhbGl0eTM2OQ==" title="https:&#x2F;&#x2F;github.com&#x2F;Gality369"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS95b3VybmFtZQ==" title="https:&#x2F;&#x2F;twitter.com&#x2F;yourname"><i class="ic i-twitter"></i></span> <a href="https://gality.cn/about/" title="https:&#x2F;&#x2F;gality.cn&#x2F;about&#x2F;" class="item about"><i class="ic i-address-card"></i></a> <span class="exturl item email" data-url="bWFpbHRvOjQzNDQwMDcyNkBxcS5jb20=" title="mailto:434400726@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>小伙伴</a></li><li class="item"><a href="/links/" rel="section"><i class="ic i-magic"></i>资源</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/scientific-research/thesis-reading/%20Blockchain%20Imitation%20Game/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/ml/transformer/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/os/" title="分类于 操作系统">操作系统</a> <i class="ic i-angle-right"></i> <a href="/categories/os/kernel/" title="分类于 内核">内核</a></div><span><a href="/os/kernel/build-kernel/" title="从0开始构建Linux内核">从0开始构建Linux内核</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="分类于 杂项">杂项</a> <i class="ic i-angle-right"></i> <a href="/categories/misc/trail-and-error/" title="分类于 踩坑">踩坑</a></div><span><a href="/misc/trail-and-error/RTX4080-tensorflow2/" title="在 RTX 4080 上运行 tensorflow 2">在 RTX 4080 上运行 tensorflow 2</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="分类于 杂项">杂项</a> <i class="ic i-angle-right"></i> <a href="/categories/misc/trail-and-error/" title="分类于 踩坑">踩坑</a></div><span><a href="/misc/trail-and-error/Mac%E4%B8%8B%E4%BD%BF%E7%94%A8GDB/" title="Mac下使用GDB进行调试">Mac下使用GDB进行调试</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/ponder/" title="分类于 思考与沉淀">思考与沉淀</a></div><span><a href="/ponder/%E9%9D%A2%E8%AF%95%E5%A4%8D%E7%9B%98/" title="科技协会面试反思与总结">科技协会面试反思与总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 学习笔记">学习笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/note/PNT/" title="分类于 PNT">PNT</a></div><span><a href="/note/PNT/timing/" title="授时过程详述">授时过程详述</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/note/" title="分类于 学习笔记">学习笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/note/PNT/" title="分类于 PNT">PNT</a></div><span><a href="/note/PNT/fiber-optic-and-WDM/" title="光纤通信原理与技术">光纤通信原理与技术</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/os/" title="分类于 操作系统">操作系统</a> <i class="ic i-angle-right"></i> <a href="/categories/os/0-1/" title="分类于 从 0 到 1">从 0 到 1</a></div><span><a href="/os/02-mbr/" title="02-从BIOS启动到MBR编写">02-从BIOS启动到MBR编写</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/os/" title="分类于 操作系统">操作系统</a> <i class="ic i-angle-right"></i> <a href="/categories/os/0-1/" title="分类于 从 0 到 1">从 0 到 1</a></div><span><a href="/os/03-loader/" title="03-Loader编写之进入保护模式">03-Loader编写之进入保护模式</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="分类于 杂项">杂项</a> <i class="ic i-angle-right"></i> <a href="/categories/misc/trail-and-error/" title="分类于 踩坑">踩坑</a></div><span><a href="/misc/trail-and-error/ubuntu%E6%89%A9%E5%AE%B9/" title="Ubuntu虚拟机扩展磁盘 ｜ 命令行 | LVM">Ubuntu虚拟机扩展磁盘 ｜ 命令行 | LVM</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/misc/" title="分类于 杂项">杂项</a> <i class="ic i-angle-right"></i> <a href="/categories/misc/trail-and-error/" title="分类于 踩坑">踩坑</a></div><span><a href="/misc/trail-and-error/blog%E6%90%AD%E5%BB%BA/" title="blog搭建&amp;Hello world">blog搭建&Hello world</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2023 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Gality @ Samadhi</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">182k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">5:32</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"ml/CNN/",favicon:{show:"（●´3｀●）哎呀呀～",hide:"(´Д｀)吓死你"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="//cdn.jsdelivr.net/gh/gality369/gality369.github.io@latest/js/app.js?v=0.2.5"></script></body></html>